{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 13 Project\n",
        "\n",
        "This week's project will build a simple agent using language models and tools.\n",
        "You will integrate the Gemini language model API with custom tools that you create to assist in task automation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WYyZ5ipiguK"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub: [Project 13 Materials](https://github.com/bu-cds-dx704/dx704-project-13).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ATR6uEFeBE0"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEGX_TFVZdEH"
      },
      "source": [
        "## Part 0: Gemini Tool Example\n",
        "\n",
        "Review the code and its output below to get an idea for how the Gemini API uses tools."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVfDl6ZbZ5bS"
      },
      "source": [
        "* https://ai.google.dev/gemini-api/docs/tools\n",
        "* https://ai.google.dev/gemini-api/docs/function-calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qiYaH35WXvA0"
      },
      "outputs": [],
      "source": [
        "%pip install -q google-genai genanki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BFvDzxu4Xxu9"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "\n",
        "import genanki\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2m98xdlvX2CW"
      },
      "outputs": [],
      "source": [
        "client = genai.Client(api_key=userdata.get('GEMINI_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b_oJ2e4qX4gm"
      },
      "outputs": [],
      "source": [
        "# Rate limit documentation https://ai.google.dev/gemini-api/docs/rate-limits\n",
        "model_name = 'gemini-2.0-flash' #'gemini-2.0-flash'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hy5hyvJJZkjy"
      },
      "outputs": [],
      "source": [
        "change_light_array_function = {\n",
        "    \"name\": \"change_light_array\",\n",
        "    \"description\": \"Change the color of a light in a 64x64 array of LEDs.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"red\": {\"type\": \"integer\", \"description\": \"Red value of the color.\"},\n",
        "            \"green\": {\"type\": \"integer\", \"description\": \"Green value of the color.\"},\n",
        "            \"blue\": {\"type\": \"integer\", \"description\": \"Blue value of the color.\"},\n",
        "            \"x\": {\"type\": \"integer\", \"description\": \"X coordinate of the light. Must be between 0 and 63 inclusive.\"},\n",
        "            \"y\": {\"type\": \"integer\", \"description\": \"Y coordinate of the light. Must be between 0 and 63 inclusive.\"},\n",
        "        },\n",
        "        \"required\": [\"red\", \"green\", \"blue\"],\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Uf0ZIqGgZpH8"
      },
      "outputs": [],
      "source": [
        "light_tools = types.Tool(function_declarations=[change_light_array_function])\n",
        "light_config = types.GenerateContentConfig(tools=[light_tools])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4PPKK2UZrCc",
        "outputId": "41f068d1-a003-4cba-9e0f-fa9b3d5c8430"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerateContentResponse(\n",
              "  candidates=[\n",
              "    Candidate(\n",
              "      avg_logprobs=-0.009899320205052693,\n",
              "      content=Content(\n",
              "        parts=[\n",
              "          Part(\n",
              "            function_call=FunctionCall(\n",
              "              args=<... Max depth ...>,\n",
              "              name=<... Max depth ...>\n",
              "            )\n",
              "          ),\n",
              "        ],\n",
              "        role='model'\n",
              "      ),\n",
              "      finish_reason=<FinishReason.STOP: 'STOP'>\n",
              "    ),\n",
              "  ],\n",
              "  model_version='gemini-2.0-flash',\n",
              "  response_id='0TUvaaeuJK7g_uMPh6LnMQ',\n",
              "  sdk_http_response=HttpResponse(\n",
              "    headers=<dict len=10>\n",
              "  ),\n",
              "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
              "    candidates_token_count=15,\n",
              "    candidates_tokens_details=[\n",
              "      ModalityTokenCount(\n",
              "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
              "        token_count=15\n",
              "      ),\n",
              "    ],\n",
              "    prompt_token_count=102,\n",
              "    prompt_tokens_details=[\n",
              "      ModalityTokenCount(\n",
              "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
              "        token_count=102\n",
              "      ),\n",
              "    ],\n",
              "    total_token_count=117\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "light_response = client.models.generate_content(\n",
        "    contents=\"Set the light at 3,3 to be chartreuse.\",\n",
        "    config=light_config,\n",
        "    model=model_name\n",
        ")\n",
        "light_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzDV1kR0ZuE5",
        "outputId": "8041305c-d539-4060-bdae-934e2bd4ba9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FunctionCall(\n",
              "  args={\n",
              "    'blue': 0,\n",
              "    'green': 255,\n",
              "    'red': 127,\n",
              "    'x': 3,\n",
              "    'y': 3\n",
              "  },\n",
              "  name='change_light_array'\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "light_response.candidates[0].content.parts[0].function_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 1: Implement Agent Logging\n",
        "\n",
        "The Agent class below uses the Gemini API's tool support to provide a chat interface that can use tools.\n",
        "Modify the Agent class to save a transcript with the name AGENT_NAME.txt where AGENT_NAME is the name used when creating the Agent object.\n",
        "Anything in the `contents` list inside the `run` method should be saved to that file.\n",
        "Test your code with the `plain_agent` setup below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iZhRWmhzXqRm"
      },
      "outputs": [],
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, name, introduction, prompt, model=\"gemini-2.0-flash\"):\n",
        "        self.name = name\n",
        "        self.introduction = introduction\n",
        "        self.prompt = prompt\n",
        "        self.model = model\n",
        "\n",
        "        self.function_declarations = {}\n",
        "        self.functions = {}\n",
        "\n",
        "    def predict(self, contents, **kwargs):\n",
        "        kwargs.setdefault('model', self.model)\n",
        "        # Pass the system instruction (prompt) here if supported, or prepend it.\n",
        "        # For simplicity with this specific starter code, we rely on the conversation history.\n",
        "        return client.models.generate_content(contents=contents, **kwargs)\n",
        "\n",
        "    def register_tool(self, function, **function_declaration):\n",
        "        if \"name\" not in function_declaration:\n",
        "            function_declaration[\"name\"] = function.__name__\n",
        "\n",
        "        function_name = function_declaration[\"name\"]\n",
        "        assert \"description\" in function_declaration\n",
        "        assert \"parameters\" in function_declaration\n",
        "\n",
        "        self.function_declarations[function_name] = function_declaration\n",
        "        self.functions[function_name] = function\n",
        "\n",
        "    def run(self):\n",
        "        print(\"RUNNING WITH TOOLS\", list(self.functions.keys()))\n",
        "        # Only create tool config if tools exist\n",
        "        if self.functions:\n",
        "            tools = types.Tool(function_declarations=list(self.function_declarations.values()))\n",
        "            config = types.GenerateContentConfig(tools=[tools])\n",
        "        else:\n",
        "            config = None\n",
        "\n",
        "        print(self.introduction, \"\\n\\n\")\n",
        "\n",
        "        # Initialize contents with the prompt to ensure the model behaves as instructed\n",
        "        contents = [self.prompt]\n",
        "\n",
        "        while True:\n",
        "            p = input(\"> \")\n",
        "            if p.strip().lower() in (\"stop\", \"quit\", \"exit\"):\n",
        "                break\n",
        "\n",
        "            contents.append(p)\n",
        "\n",
        "            # Call predict\n",
        "            if config:\n",
        "                response = self.predict(contents=contents, config=config)\n",
        "            else:\n",
        "                response = self.predict(contents=contents)\n",
        "\n",
        "            for new_content_part in response.candidates[0].content.parts:\n",
        "                if new_content_part.text:\n",
        "                    print(\"TEXT\", new_content_part.text)\n",
        "                    contents.append(new_content_part.text)\n",
        "                elif new_content_part.function_call:\n",
        "                    call = new_content_part.function_call\n",
        "                    print(\"FUNCTION CALL\", call)\n",
        "                    # We append the function call to history so the model knows it made the call\n",
        "                    # Note: handling exact object types for history can be tricky,\n",
        "                    # but simple appending often works for this specific class structure.\n",
        "\n",
        "                    if call.name in self.functions:\n",
        "                        output = self.functions[call.name](**call.args)\n",
        "                        if output:\n",
        "                            print(\"OUTPUT\", output)\n",
        "                            contents.append(output) # Append tool output\n",
        "                    else:\n",
        "                        print(\"UNRECOGNIZED FUNCTION\", call.name)\n",
        "                else:\n",
        "                    print(\"UNKNOWN\", new_content_part)\n",
        "\n",
        "        # --- MODIFIED SECTION: SAVE TRANSCRIPT ---\n",
        "        filename = f\"{self.name}.txt\"\n",
        "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            for item in contents:\n",
        "                f.write(str(item) + \"\\n\")\n",
        "        print(f\"Transcript saved to {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3J4zci0BaCUR"
      },
      "outputs": [],
      "source": [
        "plain_agent = Agent(name=\"plain\",\n",
        "                    introduction=\"Hi, I am PlainGPT and I have no tools.\",\n",
        "                    prompt=\"You are a helpful agent that is eager to help but you have no tools.\",\n",
        "                    model=\"gemini-2.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyIjxLmgaWgs",
        "outputId": "8e91a65f-b063-40ac-9685-af77edbe015e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUNNING WITH TOOLS []\n",
            "Hi, I am PlainGPT and I have no tools. \n",
            "\n",
            "\n",
            "> Hi\n",
            "TEXT Hello there! It's lovely to hear from you. How can I help you today?\n",
            "> Quit\n",
            "Transcript saved to plain.txt\n"
          ]
        }
      ],
      "source": [
        "plain_agent.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELfG1iuUau5g"
      },
      "source": [
        "Submit \"plain.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_bzhRdQYLJ4"
      },
      "source": [
        "## Part 2: Test the Agent Code\n",
        "\n",
        "Use the color agent below and instruct the agent to show you the colors blue, red, and cyan.\n",
        "After the agent has shown those colors, make sure to end the `run` method cleanly by telling the agent stop, quit, or exit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noH-BI_-ZA_T"
      },
      "source": [
        "You will notice that the language model's behavior is different from other language models or even normal Gemini since it is working with a restricted set of tools.\n",
        "You may change the agent code if you wish (e.g. to change the model or give it more tools), but be careful not to change the information stored to the contents list and the log file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkn7OAgnY-Kt"
      },
      "source": [
        "Hint: The RGB values for blue are (0, 0, 255), the RGB values for red are (255, 0, 0) and the RGB values for cyan are (0, 255, 255).\n",
        "The auto-grader will be checking for those values in your log file, so make sure that the agent shows you the right colors.\n",
        "Ideally, you can get it to figure out those values on its own, but in the worst case you can tell the agent the RGB values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8ukK8rQubUOV"
      },
      "outputs": [],
      "source": [
        "def show_color(red, green, blue):\n",
        "    plt.imshow([[[red, green, blue]]])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    return f\"Red: {red}, Green: {green}, Blue: {blue}\"\n",
        "\n",
        "color_agent = Agent(name=\"color\",\n",
        "                    introduction=\"Hi, I am ColorGPT and I know every color.\",\n",
        "                    prompt=\"You are a helpful agent that is eager to show off your color knowledge.\",\n",
        "                    model=\"gemini-2.5-pro\")\n",
        "color_agent.register_tool(show_color,\n",
        "                          description=\"Show a color!\",\n",
        "                          parameters = {\"type\": \"object\",\n",
        "                                         \"properties\": {\n",
        "                                             \"red\": {\"type\": \"integer\", \"description\": \"Red value of the color.\"},\n",
        "                                             \"green\": {\"type\": \"integer\", \"description\": \"Green value of the color.\"},\n",
        "                                             \"blue\": {\"type\": \"integer\", \"description\": \"Blue value of the color.\"}\n",
        "                                         }, \"required\": [\"red\", \"green\", \"blue\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3PypBxLicEZC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a723abe-4e57-4e50-bf4f-10bc58ea924c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUNNING WITH TOOLS ['show_color']\n",
            "Hi, I am ColorGPT and I know every color. \n",
            "\n",
            "\n",
            "> Show me the color Blue. (Red: 0, Green: 0, Blue: 255)\n",
            "FUNCTION CALL id=None args={'green': 0, 'blue': 255, 'red': 0} name='show_color' partial_args=None will_continue=None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPZJREFUeJzt2yEOxDAMAMHk1P9/2ccWh0QtmMEGZisD75mZBQBrrd/bCwDwHaIAQEQBgIgCABEFACIKAEQUAIgoAJDndHDvm2sAcNvJq7JLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAPKeDMzfXAOALXAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAOQP5Z8LCEaY2ssAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTPUT Red: 0, Green: 0, Blue: 255\n",
            "> Show me the color Red. (Red: 255, Green: 0, Blue: 0)\n",
            "FUNCTION CALL id=None args={'red': 255, 'blue': 0, 'green': 0} name='show_color' partial_args=None will_continue=None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPZJREFUeJzt2yEOxDAMAMHk1P9/2ccWh0QtmMEGZisD75mZBQBrrd/bCwDwHaIAQEQBgIgCABEFACIKAEQUAIgoAJDneHLvi2sAcN3Br7JLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAPMeTMxfXAOALXAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAOQP4aELCE0K+pYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTPUT Red: 255, Green: 0, Blue: 0\n",
            "> Show me the color Cyan. (Red: 0, Green: 255, Blue: 255)\n",
            "FUNCTION CALL id=None args={'red': 0, 'blue': 255, 'green': 255} name='show_color' partial_args=None will_continue=None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABPRJREFUeJzt2yESgDAMAMHC8P8vB3e6pgNiV0fE3UTkmplZALDWur9eAID/EAUAIgoARBQAiCgAEFEAIKIAQEQBgDy7g9fJLQA4budT2aUAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAECe3cE5uQUAv+BSACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgL6/dCQmZho0iAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTPUT Red: 0, Green: 255, Blue: 255\n",
            "> quit\n",
            "Transcript saved to color.txt\n"
          ]
        }
      ],
      "source": [
        "color_agent.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CphbWNuQcGfy"
      },
      "source": [
        "Submit \"color.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7qwYi-CcL7U"
      },
      "source": [
        "## Part 3: Modify Anki Flashcard Agent\n",
        "\n",
        "[Anki](https://apps.ankiweb.net/) is a program to help memorization using Flashcards.\n",
        "(Professor Considine uses Anki to learn foreign language vocabulary.)\n",
        "The agent that follows can create an Anki \"deck\" and add notes to create flashcards.\n",
        "However, the save functionality has not yet been integrated as a tool for the agent.\n",
        "Implement that functionality and then test it by instructing the agent to save an empty deck as \"empty.apkg\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UrSvsGLac_sR"
      },
      "outputs": [],
      "source": [
        "# Simple Model setup from https://github.com/kerrickstaley/genanki?tab=readme-ov-file#models\n",
        "# this defines a model of flashcards with just two fields, question for the front, and answer for the back.\n",
        "\n",
        "simple_model = genanki.Model(\n",
        "    1607392319,\n",
        "    'Simple Model',\n",
        "    fields=[\n",
        "        {'name': 'Question'},\n",
        "        {'name': 'Answer'},\n",
        "    ],\n",
        "    templates=[\n",
        "        {\n",
        "        'name': 'Card 1',\n",
        "        'qfmt': '{{Question}}',\n",
        "        'afmt': '{{FrontSide}}<hr id=\"answer\">{{Answer}}',\n",
        "        },\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Z6J9-951dEbD"
      },
      "outputs": [],
      "source": [
        "anki_decks = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "z_TANUF3dF8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9fe1c0-dda1-4fed-bef7-7b8d16c25452"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<genanki.deck.Deck at 0x7c140978d760>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "def get_deck(deck_name):\n",
        "    if deck_name not in anki_decks:\n",
        "        hash = hashlib.sha256(deck_name.encode('utf-8')).hexdigest()\n",
        "        hash = hash[:12]\n",
        "        hash = int(hash, 16)\n",
        "        anki_decks[deck_name] = genanki.deck.Deck(deck_id=hash, name=deck_name)\n",
        "        anki_decks[deck_name].add_model(simple_model)\n",
        "\n",
        "    return anki_decks[deck_name]\n",
        "\n",
        "get_deck(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hGcP0sBVdHl_"
      },
      "outputs": [],
      "source": [
        "anki_agent = Agent(name=\"anki\",\n",
        "                   introduction=\"Hi, I am AnkiGPT and I can help you build Anki flashcard decks.\",\n",
        "                   prompt=\"You are a helpful AI that helps lookup content for flashcards and then makes the flashcards.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pgJbXt3xfEeV"
      },
      "outputs": [],
      "source": [
        "def create_anki_note(front, back, deck):\n",
        "    get_deck(deck).add_note(genanki.Note(model=simple_model, fields=[front, back]))\n",
        "    return f\"Created note in Anki deck {deck!r}\"\n",
        "\n",
        "anki_agent.register_tool(create_anki_note,\n",
        "    description=\"Create a note in an Anki flashcard deck.\",\n",
        "    parameters= {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"front\": {\"type\": \"string\", \"description\": \"Content for front side of flash card.\"},\n",
        "            \"back\": {\"type\": \"string\", \"description\": \"Content for back side of flash card.\"},\n",
        "            \"deck\": {\"type\": \"string\", \"description\": \"Name of the Anki deck to add the note to.\"},\n",
        "        },\n",
        "        \"required\": [\"front\", \"back\", \"deck\"],\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Cl9zRB-4fGR-"
      },
      "outputs": [],
      "source": [
        "def save_anki_deck(deck):\n",
        "    genanki.Package(get_deck(deck)).write_to_file(f\"{deck}.apkg\")\n",
        "    return f\"Saved Anki deck {deck!r} to file.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rSTqBfLJfKty"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "anki_agent.register_tool(save_anki_deck,\n",
        "    description=\"Save the Anki deck to a package file (.apkg).\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"deck\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The name of the deck to save.\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"deck\"]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EoiJO0qyfZd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd9625a-5de7-4c11-9859-af680488a829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUNNING WITH TOOLS ['create_anki_note', 'save_anki_deck']\n",
            "Hi, I am AnkiGPT and I can help you build Anki flashcard decks. \n",
            "\n",
            "\n",
            "> Please save the deck \"empty\" to a file.\n",
            "FUNCTION CALL id=None args={'deck': 'empty'} name='save_anki_deck' partial_args=None will_continue=None\n",
            "OUTPUT Saved Anki deck 'empty' to file.\n",
            "> quit\n",
            "Transcript saved to anki.txt\n"
          ]
        }
      ],
      "source": [
        "anki_agent.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0F1k-AJfbQx"
      },
      "source": [
        "Submit \"empty.apkg\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Dmj8QqfmqW"
      },
      "source": [
        "## Part 4: Make an Anki Deck with Flashcards\n",
        "\n",
        "Run the Anki agent again, and instruct it to make 10 flashcards on a topic of your choice.\n",
        "If possible, have the agent supply the answers to your questions.\n",
        "When you are done, save the deck with an appropriate name (but not \"empty.apkg\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NSc-khClgEDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64c93c9-b413-453f-8230-9bdd338670fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUNNING WITH TOOLS ['create_anki_note', 'save_anki_deck']\n",
            "Hi, I am AnkiGPT and I can help you build Anki flashcard decks. \n",
            "\n",
            "\n",
            "> Create a new deck called \"Capitals\". Add 10 flashcards to it where the front is a Country and the back is its Capital City. Then save the deck.\n",
            "TEXT I can create those flashcards for you. Here are the country/capital pairs I will use:\n",
            "\n",
            "*   **United States:** Washington, D.C.\n",
            "*   **Canada:** Ottawa\n",
            "*   **United Kingdom:** London\n",
            "*   **France:** Paris\n",
            "*   **Germany:** Berlin\n",
            "*   **Japan:** Tokyo\n",
            "*   **China:** Beijing\n",
            "*   **India:** New Delhi\n",
            "*   **Brazil:** Brasília\n",
            "*   **Australia:** Canberra\n",
            "\n",
            "I will now create the flashcards and save the deck.\n",
            "\n",
            "FUNCTION CALL id=None args={'back': 'Washington, D.C.', 'deck': 'Capitals', 'front': 'United States'} name='create_anki_note' partial_args=None will_continue=None\n",
            "OUTPUT Created note in Anki deck 'Capitals'\n",
            "FUNCTION CALL id=None args={'deck': 'Capitals', 'back': 'Ottawa', 'front': 'Canada'} name='create_anki_note' partial_args=None will_continue=None\n",
            "OUTPUT Created note in Anki deck 'Capitals'\n",
            "FUNCTION CALL id=None args={'back': 'London', 'deck': 'Capitals', 'front': 'United Kingdom'} name='create_anki_note' partial_args=None will_continue=None\n",
            "OUTPUT Created note in Anki deck 'Capitals'\n",
            "FUNCTION CALL id=None args={'deck': 'Capitals', 'back': 'Paris', 'front': 'France'} name='create_anki_note' partial_args=None will_continue=None\n",
            "OUTPUT Created note in Anki deck 'Capitals'\n",
            "FUNCTION CALL id=None args={'front': 'Germany', 'back': 'Berlin', 'deck': 'Capitals'} name='create_anki_note' partial_args=None will_continue=None\n",
            "OUTPUT Created note in Anki deck 'Capitals'\n",
            "FUNCTION CALL id=None args={'back': 'Tokyo', 'front': 'Japan', 'deck': 'Capitals'} name='create_anki_note' partial_args=None will_continue=None\n",
            "OUTPUT Created note in Anki deck 'Capitals'\n",
            "FUNCTION CALL id=None args={'front': 'China', 'deck': 'Capitals', 'back': 'Beijing'} name='create_anki_note' partial_args=None will_continue=None\n",
            "OUTPUT Created note in Anki deck 'Capitals'\n",
            "FUNCTION CALL id=None args={'back': 'New Delhi', 'front': 'India', 'deck': 'Capitals'} name='create_anki_note' partial_args=None will_continue=None\n",
            "OUTPUT Created note in Anki deck 'Capitals'\n",
            "FUNCTION CALL id=None args={'deck': 'Capitals', 'front': 'Brazil', 'back': 'Brasília'} name='create_anki_note' partial_args=None will_continue=None\n",
            "OUTPUT Created note in Anki deck 'Capitals'\n",
            "FUNCTION CALL id=None args={'front': 'Australia', 'back': 'Canberra', 'deck': 'Capitals'} name='create_anki_note' partial_args=None will_continue=None\n",
            "OUTPUT Created note in Anki deck 'Capitals'\n",
            "FUNCTION CALL id=None args={'deck': 'Capitals'} name='save_anki_deck' partial_args=None will_continue=None\n",
            "OUTPUT Saved Anki deck 'Capitals' to file.\n",
            "> quit\n",
            "Transcript saved to anki.txt\n"
          ]
        }
      ],
      "source": [
        "anki_agent.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A0WQDkGgIKJ"
      },
      "source": [
        "Submit \"anki.txt\" from making flashcards and the .apkg file with your flashcards in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 5: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 6: Acknowledgements\n",
        "\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you did this assignment completely on your own, simply write none below.\n",
        "\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for. If you did not use any other libraries, simply write none below.\n",
        "\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy. If you did not use any generative AI tools, simply write none below."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}